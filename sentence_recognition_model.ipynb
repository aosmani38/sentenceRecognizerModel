{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-02T07:43:13.721112Z",
     "start_time": "2023-09-02T07:43:13.155004Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16777/16777 [00:00<00:00, 31934.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "try: [tf.config.experimental.set_memory_growth(gpu, True) for gpu in tf.config.experimental.list_physical_devices(\"GPU\")]\n",
    "except: pass\n",
    "\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from mltu.preprocessors import ImageReader\n",
    "from mltu.transformers import ImageResizer, LabelIndexer, LabelPadding, ImageShowCV2\n",
    "from mltu.augmentors import RandomBrightness, RandomRotate, RandomErodeDilate, RandomSharpen\n",
    "\n",
    "\n",
    "from mltu.tensorflow.dataProvider import DataProvider\n",
    "from mltu.tensorflow.losses import CTCloss\n",
    "from mltu.tensorflow.callbacks import Model2onnx, TrainLogger\n",
    "from mltu.tensorflow.metrics import CERMetric, WERMetric\n",
    "\n",
    "from model import train_model\n",
    "\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from keras import backend as K\n",
    "import torch\n",
    "\n",
    "# Must download and extract datasets manually from https://fki.tic.heia-fr.ch/databases/download-the-iam-handwriting-database to Datasets\\IAM_Sentences\n",
    "sentences_txt_path = os.path.join(\"Datasets\", \"IAM_Sentences\", \"ascii\", \"sentences.txt\")\n",
    "sentences_folder_path = os.path.join(\"Datasets\", \"IAM_Sentences\", \"sentences\")\n",
    "\n",
    "dataset, vocab, max_len = [], set(), 0\n",
    "words = open(sentences_txt_path, \"r\").readlines()\n",
    "for line in tqdm(words):\n",
    "    if line.startswith(\"#\"):\n",
    "        continue\n",
    "\n",
    "    line_split = line.split(\" \")\n",
    "    if line_split[2] == \"err\":\n",
    "        continue\n",
    "\n",
    "    folder1 = line_split[0][:3]\n",
    "    folder2 = \"-\".join(line_split[0].split(\"-\")[:2])\n",
    "    file_name = line_split[0] + \".png\"\n",
    "    label = line_split[-1].rstrip(\"\\n\")\n",
    "\n",
    "    # replace \"|\" with \" \" in label\n",
    "    label = label.replace(\"|\", \" \")\n",
    "\n",
    "    rel_path = os.path.join(sentences_folder_path, folder1, folder2, file_name)\n",
    "    if not os.path.exists(rel_path):\n",
    "        print(f\"File not found: {rel_path}\")\n",
    "        continue\n",
    "\n",
    "    dataset.append([rel_path, label])\n",
    "    vocab.update(list(label))\n",
    "    max_len = max(max_len, len(label))\n",
    "\n",
    "print(tf.test.is_gpu_available())\n",
    "# print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "# print(\"TensorFlow ROCm version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "______________________________________________________________________________________________________________\n",
      " Layer (type)                    Output Shape                     Param #    Connected to                     \n",
      "==============================================================================================================\n",
      " input (InputLayer)              [(None, 96, 1408, 3)]            0          []                               \n",
      "                                                                                                              \n",
      " lambda (Lambda)                 (None, 96, 1408, 3)              0          ['input[0][0]']                  \n",
      "                                                                                                              \n",
      " conv2d (Conv2D)                 (None, 96, 1408, 32)             896        ['lambda[0][0]']                 \n",
      "                                                                                                              \n",
      " batch_normalization (BatchNorm  (None, 96, 1408, 32)             128        ['conv2d[0][0]']                 \n",
      " alization)                                                                                                   \n",
      "                                                                                                              \n",
      " leaky_re_lu (LeakyReLU)         (None, 96, 1408, 32)             0          ['batch_normalization[0][0]']    \n",
      "                                                                                                              \n",
      " conv2d_1 (Conv2D)               (None, 96, 1408, 32)             9248       ['leaky_re_lu[0][0]']            \n",
      "                                                                                                              \n",
      " batch_normalization_1 (BatchNo  (None, 96, 1408, 32)             128        ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " conv2d_2 (Conv2D)               (None, 96, 1408, 32)             128        ['lambda[0][0]']                 \n",
      "                                                                                                              \n",
      " add (Add)                       (None, 96, 1408, 32)             0          ['batch_normalization_1[0][0]',  \n",
      "                                                                              'conv2d_2[0][0]']               \n",
      "                                                                                                              \n",
      " leaky_re_lu_1 (LeakyReLU)       (None, 96, 1408, 32)             0          ['add[0][0]']                    \n",
      "                                                                                                              \n",
      " dropout (Dropout)               (None, 96, 1408, 32)             0          ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                              \n",
      " conv2d_3 (Conv2D)               (None, 48, 704, 32)              9248       ['dropout[0][0]']                \n",
      "                                                                                                              \n",
      " batch_normalization_2 (BatchNo  (None, 48, 704, 32)              128        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " leaky_re_lu_2 (LeakyReLU)       (None, 48, 704, 32)              0          ['batch_normalization_2[0][0]']  \n",
      "                                                                                                              \n",
      " conv2d_4 (Conv2D)               (None, 48, 704, 32)              9248       ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                              \n",
      " batch_normalization_3 (BatchNo  (None, 48, 704, 32)              128        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " conv2d_5 (Conv2D)               (None, 48, 704, 32)              1056       ['dropout[0][0]']                \n",
      "                                                                                                              \n",
      " add_1 (Add)                     (None, 48, 704, 32)              0          ['batch_normalization_3[0][0]',  \n",
      "                                                                              'conv2d_5[0][0]']               \n",
      "                                                                                                              \n",
      " leaky_re_lu_3 (LeakyReLU)       (None, 48, 704, 32)              0          ['add_1[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_1 (Dropout)             (None, 48, 704, 32)              0          ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                              \n",
      " conv2d_6 (Conv2D)               (None, 48, 704, 32)              9248       ['dropout_1[0][0]']              \n",
      "                                                                                                              \n",
      " batch_normalization_4 (BatchNo  (None, 48, 704, 32)              128        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " leaky_re_lu_4 (LeakyReLU)       (None, 48, 704, 32)              0          ['batch_normalization_4[0][0]']  \n",
      "                                                                                                              \n",
      " conv2d_7 (Conv2D)               (None, 48, 704, 32)              9248       ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                              \n",
      " batch_normalization_5 (BatchNo  (None, 48, 704, 32)              128        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " add_2 (Add)                     (None, 48, 704, 32)              0          ['batch_normalization_5[0][0]',  \n",
      "                                                                              'dropout_1[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_5 (LeakyReLU)       (None, 48, 704, 32)              0          ['add_2[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_2 (Dropout)             (None, 48, 704, 32)              0          ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                              \n",
      " conv2d_8 (Conv2D)               (None, 24, 352, 64)              18496      ['dropout_2[0][0]']              \n",
      "                                                                                                              \n",
      " batch_normalization_6 (BatchNo  (None, 24, 352, 64)              256        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " leaky_re_lu_6 (LeakyReLU)       (None, 24, 352, 64)              0          ['batch_normalization_6[0][0]']  \n",
      "                                                                                                              \n",
      " conv2d_9 (Conv2D)               (None, 24, 352, 64)              36928      ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                              \n",
      " batch_normalization_7 (BatchNo  (None, 24, 352, 64)              256        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " conv2d_10 (Conv2D)              (None, 24, 352, 64)              2112       ['dropout_2[0][0]']              \n",
      "                                                                                                              \n",
      " add_3 (Add)                     (None, 24, 352, 64)              0          ['batch_normalization_7[0][0]',  \n",
      "                                                                              'conv2d_10[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_7 (LeakyReLU)       (None, 24, 352, 64)              0          ['add_3[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_3 (Dropout)             (None, 24, 352, 64)              0          ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                              \n",
      " conv2d_11 (Conv2D)              (None, 24, 352, 64)              36928      ['dropout_3[0][0]']              \n",
      "                                                                                                              \n",
      " batch_normalization_8 (BatchNo  (None, 24, 352, 64)              256        ['conv2d_11[0][0]']              \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " leaky_re_lu_8 (LeakyReLU)       (None, 24, 352, 64)              0          ['batch_normalization_8[0][0]']  \n",
      "                                                                                                              \n",
      " conv2d_12 (Conv2D)              (None, 24, 352, 64)              36928      ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                              \n",
      " batch_normalization_9 (BatchNo  (None, 24, 352, 64)              256        ['conv2d_12[0][0]']              \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " add_4 (Add)                     (None, 24, 352, 64)              0          ['batch_normalization_9[0][0]',  \n",
      "                                                                              'dropout_3[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_9 (LeakyReLU)       (None, 24, 352, 64)              0          ['add_4[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_4 (Dropout)             (None, 24, 352, 64)              0          ['leaky_re_lu_9[0][0]']          \n",
      "                                                                                                              \n",
      " conv2d_13 (Conv2D)              (None, 12, 176, 128)             73856      ['dropout_4[0][0]']              \n",
      "                                                                                                              \n",
      " batch_normalization_10 (BatchN  (None, 12, 176, 128)             512        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_10 (LeakyReLU)      (None, 12, 176, 128)             0          ['batch_normalization_10[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_14 (Conv2D)              (None, 12, 176, 128)             147584     ['leaky_re_lu_10[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_11 (BatchN  (None, 12, 176, 128)             512        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " conv2d_15 (Conv2D)              (None, 12, 176, 128)             8320       ['dropout_4[0][0]']              \n",
      "                                                                                                              \n",
      " add_5 (Add)                     (None, 12, 176, 128)             0          ['batch_normalization_11[0][0]', \n",
      "                                                                              'conv2d_15[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_11 (LeakyReLU)      (None, 12, 176, 128)             0          ['add_5[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_5 (Dropout)             (None, 12, 176, 128)             0          ['leaky_re_lu_11[0][0]']         \n",
      "                                                                                                              \n",
      " conv2d_16 (Conv2D)              (None, 12, 176, 128)             147584     ['dropout_5[0][0]']              \n",
      "                                                                                                              \n",
      " batch_normalization_12 (BatchN  (None, 12, 176, 128)             512        ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_12 (LeakyReLU)      (None, 12, 176, 128)             0          ['batch_normalization_12[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_17 (Conv2D)              (None, 12, 176, 128)             147584     ['leaky_re_lu_12[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_13 (BatchN  (None, 12, 176, 128)             512        ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " conv2d_18 (Conv2D)              (None, 12, 176, 128)             16512      ['dropout_5[0][0]']              \n",
      "                                                                                                              \n",
      " add_6 (Add)                     (None, 12, 176, 128)             0          ['batch_normalization_13[0][0]', \n",
      "                                                                              'conv2d_18[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_13 (LeakyReLU)      (None, 12, 176, 128)             0          ['add_6[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_6 (Dropout)             (None, 12, 176, 128)             0          ['leaky_re_lu_13[0][0]']         \n",
      "                                                                                                              \n",
      " conv2d_19 (Conv2D)              (None, 6, 88, 128)               147584     ['dropout_6[0][0]']              \n",
      "                                                                                                              \n",
      " batch_normalization_14 (BatchN  (None, 6, 88, 128)               512        ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_14 (LeakyReLU)      (None, 6, 88, 128)               0          ['batch_normalization_14[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_20 (Conv2D)              (None, 6, 88, 128)               147584     ['leaky_re_lu_14[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_15 (BatchN  (None, 6, 88, 128)               512        ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " conv2d_21 (Conv2D)              (None, 6, 88, 128)               16512      ['dropout_6[0][0]']              \n",
      "                                                                                                              \n",
      " add_7 (Add)                     (None, 6, 88, 128)               0          ['batch_normalization_15[0][0]', \n",
      "                                                                              'conv2d_21[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_15 (LeakyReLU)      (None, 6, 88, 128)               0          ['add_7[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_7 (Dropout)             (None, 6, 88, 128)               0          ['leaky_re_lu_15[0][0]']         \n",
      "                                                                                                              \n",
      " conv2d_22 (Conv2D)              (None, 6, 88, 128)               147584     ['dropout_7[0][0]']              \n",
      "                                                                                                              \n",
      " batch_normalization_16 (BatchN  (None, 6, 88, 128)               512        ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_16 (LeakyReLU)      (None, 6, 88, 128)               0          ['batch_normalization_16[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_23 (Conv2D)              (None, 6, 88, 128)               147584     ['leaky_re_lu_16[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_17 (BatchN  (None, 6, 88, 128)               512        ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " add_8 (Add)                     (None, 6, 88, 128)               0          ['batch_normalization_17[0][0]', \n",
      "                                                                              'dropout_7[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_17 (LeakyReLU)      (None, 6, 88, 128)               0          ['add_8[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_8 (Dropout)             (None, 6, 88, 128)               0          ['leaky_re_lu_17[0][0]']         \n",
      "                                                                                                              \n",
      " reshape (Reshape)               (None, 528, 128)                 0          ['dropout_8[0][0]']              \n",
      "                                                                                                              \n",
      " bidirectional (Bidirectional)   (None, 528, 512)                 788480     ['reshape[0][0]']                \n",
      "                                                                                                              \n",
      " dropout_9 (Dropout)             (None, 528, 512)                 0          ['bidirectional[0][0]']          \n",
      "                                                                                                              \n",
      " bidirectional_1 (Bidirectional  (None, 528, 128)                 295424     ['dropout_9[0][0]']              \n",
      " )                                                                                                            \n",
      "                                                                                                              \n",
      " dropout_10 (Dropout)            (None, 528, 128)                 0          ['bidirectional_1[0][0]']        \n",
      "                                                                                                              \n",
      " output (Dense)                  (None, 528, 80)                  10320      ['dropout_10[0][0]']             \n",
      "                                                                                                              \n",
      "==============================================================================================================\n",
      "Total params: 2428112 (9.26 MB)\n",
      "Trainable params: 2425168 (9.25 MB)\n",
      "Non-trainable params: 2944 (11.50 KB)\n",
      "______________________________________________________________________________________________________________\n",
      "Epoch 1/60\n",
      " 39/397 [=>............................] - ETA: 1:29:20 - loss: 672.5471 - CER: 1.4200 - WER: 0.9862"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 60\u001B[0m\n\u001B[0;32m     57\u001B[0m model2onnx \u001B[38;5;241m=\u001B[39m Model2onnx(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfigs\u001B[38;5;241m.\u001B[39mmodel_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/model.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     59\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_data_provider\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     62\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_data_provider\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfigs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     64\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearlystopper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainLogger\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduceLROnPlat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_callback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel2onnx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfigs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_workers\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;66;03m# Save training and validation datasets as csv files\u001B[39;00m\n\u001B[0;32m     69\u001B[0m train_data_provider\u001B[38;5;241m.\u001B[39mto_csv(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(configs\u001B[38;5;241m.\u001B[39mmodel_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "File \u001B[1;32m~\\PycharmProjects\\ECS170 Project\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ECS170 Project\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1734\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1735\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1736\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1739\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1740\u001B[0m ):\n\u001B[0;32m   1741\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1742\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1743\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1744\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\PycharmProjects\\ECS170 Project\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ECS170 Project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    822\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 825\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    827\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    828\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ECS170 Project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    854\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    855\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    856\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 857\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_no_variable_creation_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    859\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    860\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    861\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\PycharmProjects\\ECS170 Project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    146\u001B[0m   (concrete_function,\n\u001B[0;32m    147\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m--> 148\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    149\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ECS170 Project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs)\u001B[0m\n\u001B[0;32m   1345\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1346\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1347\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1348\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1349\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1350\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1351\u001B[0m     args,\n\u001B[0;32m   1352\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1353\u001B[0m     executing_eagerly)\n\u001B[0;32m   1354\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\PycharmProjects\\ECS170 Project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    195\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 196\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    200\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    201\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    202\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mlist\u001B[39m(args))\n",
      "File \u001B[1;32m~\\PycharmProjects\\ECS170 Project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1455\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1457\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1458\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1459\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1460\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1461\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1462\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1463\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1464\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1465\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1466\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1467\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1471\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1472\u001B[0m   )\n",
      "File \u001B[1;32m~\\PycharmProjects\\ECS170 Project\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from configs import ModelConfigs\n",
    "from mltu.annotations.images import CVImage\n",
    "# Create a data provider for the dataset\n",
    "configs = ModelConfigs()\n",
    "\n",
    "# Save vocab and maximum text length to configs\n",
    "configs.vocab = \"\".join(vocab)\n",
    "configs.max_text_length = max_len\n",
    "configs.save() \n",
    "\n",
    "data_provider = DataProvider(\n",
    "    dataset=dataset,\n",
    "    skip_validation=True,\n",
    "    batch_size=configs.batch_size,\n",
    "    data_preprocessors=[ImageReader(CVImage)],\n",
    "    transformers=[\n",
    "        ImageResizer(configs.width, configs.height, keep_aspect_ratio=True),\n",
    "        LabelIndexer(configs.vocab),\n",
    "        LabelPadding(max_word_length=configs.max_text_length, padding_value=len(configs.vocab)),\n",
    "        ],\n",
    ")\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data_provider, val_data_provider = data_provider.split(split = 0.9)\n",
    "\n",
    "# Augment training data with random brightness, rotation and erode/dilate\n",
    "train_data_provider.augmentors = [\n",
    "    RandomBrightness(), \n",
    "    RandomErodeDilate(),\n",
    "    RandomSharpen(),\n",
    "    ]\n",
    "\n",
    "# Creating TensorFlow model architecture\n",
    "model = train_model(\n",
    "    input_dim = (configs.height, configs.width, 3),\n",
    "    output_dim = len(configs.vocab),\n",
    ")\n",
    "\n",
    "# Compile the model and print summary\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=configs.learning_rate), \n",
    "    loss=CTCloss(), \n",
    "    metrics=[\n",
    "        CERMetric(vocabulary=configs.vocab),\n",
    "        WERMetric(vocabulary=configs.vocab)\n",
    "        ],\n",
    "    run_eagerly=False\n",
    ")\n",
    "model.summary(line_length=110)\n",
    "\n",
    "# Define callbacks\n",
    "earlystopper = EarlyStopping(monitor=\"val_CER\", patience=20, verbose=1, mode=\"min\")\n",
    "checkpoint = ModelCheckpoint(f\"{configs.model_path}/model.h5\", monitor=\"val_CER\", verbose=1, save_best_only=True, mode=\"min\")\n",
    "trainLogger = TrainLogger(configs.model_path)\n",
    "tb_callback = TensorBoard(f\"{configs.model_path}/logs\", update_freq=1)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor=\"val_CER\", factor=0.9, min_delta=1e-10, patience=5, verbose=1, mode=\"auto\")\n",
    "model2onnx = Model2onnx(f\"{configs.model_path}/model.h5\")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_data_provider,\n",
    "    validation_data=val_data_provider,\n",
    "    epochs=configs.train_epochs,\n",
    "    callbacks=[earlystopper, checkpoint, trainLogger, reduceLROnPlat, tb_callback, model2onnx],\n",
    "    workers=configs.train_workers\n",
    ")\n",
    "\n",
    "# Save training and validation datasets as csv files\n",
    "train_data_provider.to_csv(os.path.join(configs.model_path, \"train.csv\"))\n",
    "val_data_provider.to_csv(os.path.join(configs.model_path, \"val.csv\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T06:30:23.016192900Z",
     "start_time": "2023-09-02T06:20:19.128191200Z"
    }
   },
   "id": "ef04fd9cad04ff2e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
